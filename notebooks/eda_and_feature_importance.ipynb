{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b5795e",
   "metadata": {},
   "source": [
    "# EDA and Feature Importance — Used Car Price Prediction (India)\n",
    "\n",
    "This notebook loads the project dataset (prefers `data/cleaned_cars.csv`, falls back to `data/cars.csv` or `data/sample_cars.csv`), performs quick exploratory data analysis (head, basic stats, histograms, correlation heatmap), and trains a small RandomForest to show top feature importances. Cells are runnable and guarded for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ba734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Imports and setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "import sklearn\n",
    "print('scikit-learn', sklearn.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffbf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Load data (prefer cleaned)\n",
    "ROOT = Path('..') / ''\n",
    "CLEANED = Path('..') / 'data' / 'cleaned_cars.csv'\n",
    "CARS = Path('..') / 'data' / 'cars.csv'\n",
    "SAMPLE = Path('..') / 'data' / 'sample_cars.csv'\n",
    "\n",
    "if CLEANED.exists():\n",
    "    data_path = CLEANED\n",
    "elif CARS.exists():\n",
    "    data_path = CARS\n",
    "else:\n",
    "    data_path = SAMPLE\n",
    "\n",
    "print('Loading data from', str(data_path))\n",
    "df = pd.read_csv(data_path)\n",
    "print('Rows, cols:', df.shape)\n",
    "\n",
    "# show head\n",
    "display(df.head())\n",
    "\n",
    "# info and describe\n",
    "print('\\nData types:')\n",
    "print(df.dtypes)\n",
    "\n",
    "print('\\nDescriptive statistics (numeric):')\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fe267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Histograms for numeric columns\n",
    "numeric_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in ['selling_price']]\n",
    "# ensure some standard order if available\n",
    "preferred = ['age','km_driven','mileage','engine','max_power','selling_price']\n",
    "cols = [c for c in preferred if c in df.columns] + [c for c in numeric_cols if c not in preferred]\n",
    "\n",
    "n = len(cols)\n",
    "if n==0:\n",
    "    print('No numeric columns found to plot.')\n",
    "else:\n",
    "    fig, axes = plt.subplots(min(4,n), 2, figsize=(12, 3*min(4,n)))\n",
    "    axes = axes.flatten() if n>1 else [axes]\n",
    "    for i, c in enumerate(cols[:8]):\n",
    "        sns.histplot(df[c].dropna(), kde=False, ax=axes[i], color='steelblue')\n",
    "        axes[i].set_title(c)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Correlation heatmap (numeric features)\n",
    "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns]\n",
    "if len(num_cols) >= 2:\n",
    "    corr = df[num_cols].corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='vlag', center=0)\n",
    "    plt.title('Correlation matrix (numeric)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for correlation matrix.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Simple feature importance via RandomForest\n",
    "\n",
    "features = [\n",
    "    'brand','model','age','km_driven','mileage','engine','max_power','owner','fuel_type','transmission','seller_type'\n",
    "]\n",
    "features = [f for f in features if f in df.columns]\n",
    "\n",
    "if len(df) < 10:\n",
    "    print('Dataset is small (<10 rows). Skipping model training.')\n",
    "else:\n",
    "    X = df[features]\n",
    "    y = df['selling_price'] if 'selling_price' in df.columns else None\n",
    "    if y is None:\n",
    "        print('No target column `selling_price` found — cannot train model.')\n",
    "    else:\n",
    "        # numeric and categorical lists\n",
    "        numeric_feats = [c for c in ['age','km_driven','mileage','engine','max_power','owner'] if c in X.columns]\n",
    "        categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "        # build preprocessor\n",
    "        try:\n",
    "            ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        except TypeError:\n",
    "            ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', StandardScaler(), numeric_feats),\n",
    "            ('cat', ohe, categorical_feats)\n",
    "        ])\n",
    "\n",
    "        # small RandomForest for importance; keep n_estimators low for speed on small data\n",
    "        n_estimators = 50 if len(df) < 200 else 200\n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "        pipe = Pipeline([('preprocessor', preprocessor), ('model', rf)])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            pipe.fit(X_train, y_train)\n",
    "\n",
    "        preds = pipe.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, preds) ** 0.5\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        print(f'RandomForest RMSE={rmse:.2f}, R2={r2:.3f}')\n",
    "\n",
    "        # obtain feature names from preprocessor\n",
    "        try:\n",
    "            feature_names = pipe.named_steps['preprocessor'].get_feature_names_out()\n",
    "        except Exception:\n",
    "            # fallback: build names from numeric + categorical (rough)\n",
    "            ohe_categories = []\n",
    "            try:\n",
    "                ohe_cats = pipe.named_steps['preprocessor'].named_transformers_['cat'].categories_\n",
    "                for i, col in enumerate(categorical_feats):\n",
    "                    cats = ohe_cats[i]\n",
    "                    ohe_categories.extend([f\"{col}__{v}\" for v in cats])\n",
    "            except Exception:\n",
    "                ohe_categories = categorical_feats\n",
    "            feature_names = list(numeric_feats) + list(ohe_categories)\n",
    "\n",
    "        importances = pipe.named_steps['model'].feature_importances_\n",
    "        fi = pd.Series(importances, index=feature_names)\n",
    "        fi_sorted = fi.sort_values(ascending=False).head(20)\n",
    "\n",
    "        # plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=fi_sorted.values, y=fi_sorted.index, palette='viridis')\n",
    "        plt.title('Top feature importances (RandomForest)')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
